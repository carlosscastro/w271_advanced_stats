---
title: "Statistical Methods for Discrete Response, Time Series, and Panel Data (W271): Lab 2"
author: "Eric Yang, Samir Datta, Carlos Castro"
date: "OCTOBER 22, 2017"
output: pdf_document
---

# Introduction

Here we present the results of our analysis on contributions data for the university foundation, where our goal is to utilize the data available to predict who are likely to donate in the future and an idea of the magnitude of such donation.

The dataset includes, for each record, information such as:

* Donation amounts for the last 4 years
* Whether they attended the contribution events between 2012 and 2015
* Year of graduation
* Marital status, Gender
* Major of studies
* Year of graduation

Given that the goal of this study is to be able to predict who are likely to donate and the magnitude of that donation, we build a model focusing on its predictive power rather than its explanatory power. To build our model, in the following sections we thoroughly analyze the data, afterwards consider both multinomial and ordinal models and conduct statistical analysis on them to choose the one most fit for the required predictions.

As part of priorizing prediction over explanation in our models, we used a machine learning approach to testing and selecting models. We split our data in train and test set, to validate the predictions. In addition, to select the most powerful yet parsimious model predictors, we used statistical analysis, a thorough exploratory data analysis and domain knowledge.

We used confusion matrices on our models to understand exactly the strengths and weaknesses of our models' predictive power.

Finally, we selected an ordinal model that is based off the following predictors:

* AttendenceEvent: Whether they attended the donor events between 2012 and 2015
* Gender
* NextDegreeBinary: Binary variable of whether they would pursue another degree
* as.ordered(YearsSinceGrad): ordinal variable based off years since graduation (it has only 4 levels)
* log(meandonation+1) * gaveLastYear: Interaction between log of mean donation for the individual between 2012 and 2015 plus one, and whether it gave money last year or not


The sections to follow will include a thorough data analysis, starting with univariate analysis and then observing interactions with our output variable. After that, we'll do a model selection section where we explain our process towards the final model, followed by final remarks on our investigation.

# Data Analysis

## Data Loading


Note that we use two special libraries in this investigation:

* GGally: For parallel coordinate plots
* caret: For computing confusion matrices with thorough statistics

```{r}
#loading packages and data
library(ggplot2)
library(ordinal)
library(nnet)
library(caret)
library(GGally)
labdata <- read.csv('lab2data.csv')
knitr::opts_chunk$set(fig.width=8, fig.height=3) 
```

## Feature engineering

```{r}
#split major into STEM and non-STEM
labdata$MajorType <- ifelse(labdata$Major=='Biology'|labdata$Major=='Economics'|
labdata$Major=='Psychology'|labdata$Major=='Physics'|
labdata$Major=='Chemistry'|labdata$Major=='Mathematics'|
labdata$Major=='General Science-Chemistry'|labdata$Major=='Economics-Business'|
labdata$Major=='General Science-Chemistry'|labdata$Major=='Sociology-Anthropology'|
labdata$Major=='General Science-Psycho'|labdata$Major=='General Science-Math'|
labdata$Major=='General Science-Biology'|labdata$Major=='Computer Science'|
labdata$Major=='General Science'|labdata$Major=='Mathematics-Physics'|
labdata$Major=='Economics-Regional Stds.'|labdata$Major=='Zoology'|
labdata$Major=='Engineering'|labdata$Major=='Sociology'|
labdata$Major=='Anthropology'|labdata$Major=='General Science-Physics',
                            "STEM", "Non-STEM")


#create simpler variable to represent if someone has an advanced degree or not
labdata$NextDegreeBinary <- ifelse(labdata$Next.Degree=='NONE', 0, 1)

#create buckets for all years
labdata$FY16cat <- cut(labdata$FY16Giving, c(0,1,100,250,500,200000), right=F)
labdata$FY15cat <- cut(labdata$FY15Giving, c(0,1,100,250,500,200000), right=F)
labdata$FY14cat <- cut(labdata$FY14Giving, c(0,1,100,250,500,200000), right=F)
labdata$FY13cat <- cut(labdata$FY13Giving, c(0,1,100,250,500,200000), right=F)
labdata$FY12cat <- cut(labdata$FY12Giving, c(0,1,100,250,500,200000), right=F)

#turn class year into years since grad to make interpretaion easier
labdata$YearsSinceGrad <- 2017 - labdata$Class.Year

#loop through data to get each person's mean donation over the past 4 years
labdata$meandonation <- NA
for (i in c(1:1000)){
  labdata[i,]$meandonation<-mean(c(labdata[i,]$FY12Giving, 
                                    labdata[i,]$FY13Giving, 
                                    labdata[i,]$FY14Giving,
                                    labdata[i,]$FY15Giving))
}

#did they give in 2015 or not?
labdata$gaveLastYear <- ifelse(labdata$FY15Giving==0,0,1)
```



## EDA Univariate analysis

###Gender
```{r}
table(labdata$Gender)
```

Both male and female alumni are approximately evenly represented.

###Years since graduation
```{r}
table(labdata$YearsSinceGrad)
```

For the sake of an easier interpretation we transformed the varaible "Class.Year" into years since graduation by subtracting it from 2017. There are 5 unique values which reveals that this dataset polled alumni from classes 10 years apart. Younger alumni are more represented - alumni who graduated 5 years ago are represented almost 3 times as much as those who graduated 45 years ago. Already this appears to be an important variable to control for so that our model is not biased towards younger graduates. Furthermoer, due to the groups of the variable, we will want to treat this as an ordinal - instead of a continuous - variable.

###Marital.Status
```{r}
table(labdata$Marital.Status)
```

Most alumni are married, a good portion are single as well. The divorced and widowed group are sparsely represented.

###Major
```{r}
length(unique(labdata$Major))
table(labdata$MajorType)
```

There are 45 different majors with varying levels of representation, including many with only one alumnus (for the sake of saving space we have decided to not show the full list). Because of that, we condensed this variable into STEM vs. Non-STEM, both of which appear to be approximately equally represented.

###Next Degree
```{r}
table(labdata$Next.Degree)
table(labdata$NextDegreeBinary)
```

Like the Major variable, there is a variety of sparsely represented advanced degrees, so we chose to condense it into a binary variable - "None" vs. the rest. Interestingly, a considerable majority of alumni in this sample have an advanced degree, which could point to a sampling bias.

###Attendance Event

```{r}
table(labdata$AttendenceEvent)
```

A majority of alumni have attended alumni events between 2012 and 2015. This could also point to sampling bias - the dataset may come from alumni who were already more likely to donate than not.

###Previous donations
```{r}
table(labdata$FY12cat)
table(labdata$FY13cat)
table(labdata$FY14cat)
table(labdata$FY15cat)
```

From 2012 to 2015 the number of people in each donation category appears relativly stable. Higher donation categories have less alumni, with the exception of the highest category [500,2e+05) which has more than the next highest one in 3/4 years.



###FY16 category
```{r}
table(labdata$FY16cat)
```

The numbers for 2016 also look very similar to the previous years. This suggests that a large number of alumni stay in the same donation category from year to year, and that implementing information about previous years' donations will be crucial for our model's predictive ability. As we noticed before, the [250,500) category is very sparsely represented, which may make it hard to predict accurately.

### Mean donation in the past

```{r}
par(mfrow=c(1,2))
hist(labdata$meandonation)
hist(log(labdata$meandonation+1))
```

The variable mean donation, which represents each alumnus' mean donation from 2012-2015, has a large positive skew. Applying a log transformation (after adding 1, since the value 0 can't be log transformed) solves this to some extent, although a slight positive skew is still evident. A disproportionate number of alumni have a mean donation value of 0.

## EDA Relationship between FY16cat and other variables

###Parallel coordinate plot

```{r}
ggparcoord(labdata, columns = c(2, 3, 4, 7, 8, 9, 10, 11, 13, 14, 21), groupColumn = "FY16cat", scale = "uniminmax", scaleSummary = "center", title = "FY16GivingCat: Parallel Coordinate Plot") + theme(axis.text.x = element_text(angle = 90))
```



```{r}
#code to set up visualizations
labdata_counts <- with(labdata,aggregate(MajorType,list(MajorType=MajorType),length))
labdata_agg <- with(labdata, aggregate(MajorType, list(MajorType=MajorType,
                                            FY16cat=FY16cat),length))
labdata_agg <- merge(labdata_agg, labdata_counts, by="MajorType")
labdata_agg <- setNames(labdata_agg, c("MajorType", "FY16cat", "Count", "TotalCount"))
labdata_agg$percent <- 100*labdata_agg$Count/labdata_agg$TotalCount
labdata_agg$FY16cat <- factor(labdata_agg$FY16cat,
      levels=c("[500,2e+05)","[250,500)","[100,250)","[1,100)","[0,1)"))

ggp_MajorType <- ggplot(labdata_agg, aes(x=MajorType,y=percent))+ geom_bar(stat="identity", aes(fill=FY16cat))+
  ylab("% of alumni in each category")+xlab("Years since graduation")+
  scale_fill_discrete(name="Donation Category for 2016")

labdata_counts <- with(labdata,aggregate(YearsSinceGrad,list(YearsSinceGrad=YearsSinceGrad),length))
labdata_agg <- with(labdata,aggregate(YearsSinceGrad, list(YearsSinceGrad=YearsSinceGrad,FY16cat=FY16cat),length))
labdata_agg <- merge(labdata_agg, labdata_counts, by="YearsSinceGrad")
labdata_agg <- setNames(labdata_agg, c("YearsSinceGrad", "FY16cat", "Count", "TotalCount"))
labdata_agg$percent <- 100*labdata_agg$Count/labdata_agg$TotalCount
labdata_agg$FY16cat <- factor(labdata_agg$FY16cat,
      levels=c("[500,2e+05)","[250,500)","[100,250)","[1,100)","[0,1)"))

ggp_yearsincegrad <- ggplot(labdata_agg, aes(x=YearsSinceGrad,y=percent))+ geom_bar(stat="identity", aes(fill=FY16cat))+
  ylab("% of alumni in each category")+xlab("Years since graduation")+
  scale_fill_discrete(name="Donation Category for 2016")

labdata_counts <- with(labdata,aggregate(Gender,list(Gender=Gender),length))
labdata_agg <- with(labdata,aggregate(Gender, list(Gender=Gender,FY16cat=FY16cat),length))
labdata_agg <- merge(labdata_agg, labdata_counts, by="Gender")
labdata_agg <- setNames(labdata_agg, c("Gender", "FY16cat", "Count", "TotalCount"))
labdata_agg$percent <- 100*labdata_agg$Count/labdata_agg$TotalCount
labdata_agg$FY16cat <- factor(labdata_agg$FY16cat,
      levels=c("[500,2e+05)","[250,500)","[100,250)","[1,100)","[0,1)"))

ggp_gender <- ggplot(labdata_agg, aes(x=Gender,y=percent))+
  geom_bar(stat="identity", aes(fill=FY16cat))+
  ylab("% of alumni in each category")+xlab("Gender")+
  scale_fill_discrete(name="Donation Category for 2016")+guides(fill=F)

labdata_counts <- with(labdata,aggregate(AttendenceEvent,list(AttendenceEvent=AttendenceEvent),length))
labdata_agg <- with(labdata,aggregate(AttendenceEvent, list(AttendenceEvent=AttendenceEvent,FY16cat=FY16cat),length))
labdata_agg <- merge(labdata_agg, labdata_counts, by="AttendenceEvent")
labdata_agg <- setNames(labdata_agg, c("AttendenceEvent", "FY16cat", "Count", "TotalCount"))
labdata_agg$percent <- 100*labdata_agg$Count/labdata_agg$TotalCount
labdata_agg$FY16cat <- factor(labdata_agg$FY16cat,
      levels=c("[500,2e+05)","[250,500)","[100,250)","[1,100)","[0,1)"))

ggp_aevent <- ggplot(labdata_agg, aes(x=as.factor(AttendenceEvent),y=percent))+ geom_bar(stat="identity", aes(fill=FY16cat))+
  ylab("% of alumni in each category")+xlab("Donation category for 2015")+
  scale_fill_discrete(name="Donation Category for 2016")+
  xlab("Attendance Event")+scale_x_discrete(labels=c("Didn't Attend", "Attended"))

labdata_counts <- with(labdata,aggregate(NextDegreeBinary,list(NextDegreeBinary=NextDegreeBinary),length))
labdata_agg <- with(labdata,aggregate(NextDegreeBinary, list(NextDegreeBinary=NextDegreeBinary,FY16cat=FY16cat),length))
labdata_agg <- merge(labdata_agg, labdata_counts, by="NextDegreeBinary")
labdata_agg <- setNames(labdata_agg, c("NextDegreeBinary", "FY16cat", "Count", "TotalCount"))
labdata_agg$percent <- 100*labdata_agg$Count/labdata_agg$TotalCount
labdata_agg$FY16cat <- factor(labdata_agg$FY16cat,
      levels=c("[500,2e+05)","[250,500)","[100,250)","[1,100)","[0,1)"))

ggp_nextdegree <- ggplot(labdata_agg, aes(x=as.factor(NextDegreeBinary),y=percent))+ geom_bar(stat="identity", aes(fill=FY16cat))+
  ylab("% of alumni in each category")+xlab("Donation category for 2015")+
  scale_fill_discrete(name="Donation Category for 2016")+
  xlab("")+scale_x_discrete(labels=c("No Advanced Degree", "Advanced Degree"))

labdata_counts <- with(labdata,aggregate(FY15cat,list(FY15cat=FY15cat),length))
labdata_agg <- with(labdata,aggregate(FY15cat, list(FY15cat=FY15cat,FY16cat=FY16cat),
                    length))
labdata_agg <- merge(labdata_agg, labdata_counts, by="FY15cat")
labdata_agg <- setNames(labdata_agg, c("FY15cat", "FY16cat", "Count", "TotalCount"))
labdata_agg$percent <- 100*labdata_agg$Count/labdata_agg$TotalCount
labdata_agg$FY16cat <- factor(labdata_agg$FY16cat,
      levels=c("[500,2e+05)","[250,500)","[100,250)","[1,100)","[0,1)"))

ggp_FY15cat <- ggplot(labdata_agg, aes(x=FY15cat,y=percent))+ geom_bar(stat="identity", aes(fill=FY16cat))+
  ylab("% of alumni in each category")+xlab("Donation category for 2015")+
  scale_fill_discrete(name="Donation Category for 2016")
```

###Major type - STEM vs. Non-STEM
```{r}
ggp_MajorType
```
Major type does not seem to have an effect on the donation amount of an alumnnus, as the distribution of donation categories appears virtually identical regardless of whether they graduated with a STEM or non-STEM degree.



###Next Degree (binary)  
```{r}
ggp_nextdegree
```

Across all donation categories, those with an advanced degree were much more likely to donate.

###Years since graduation
```{r}
ggp_yearsincegrad
```
A clear ordinal relationship between years since grad and the amount donated in 2016 is shown in the violin plot, where those that graduated longer ago are more likely to not be in the [0,1] category and more likely to be in higher donation categories as well.

###Gender

```{r}
ggp_gender
```

Men appear to be more likely to donate in the top 3 categories, while women appear to be more likely to donate in the [1,100) category. Interestingly, both men and women appear to be just as likely to donate nothing. This may suggest that gender would be more useful for a multinomial model instead of an ordinal model.

###Attendance event
```{r}
ggp_aevent
```

Those who went to alumni events were much more likely to donate and especially more likely to donate in the higher categories.



###Donation category for the previous year (2015)
```{r}
ggp_FY15cat
```

This stacked bar graph shows what proportion of alumni that fit into donation category X went into the same - or different - category in 2016. As expected, the largest bar in each group represents the same category. That is, the majority of those who donated $0 in 2015 also donated $0 in 2016, the majority of those who donated between $1-$100 in 2015 stayed in that category the next year, etc.

A key takeaway from this visualization is the relative instability of the [1,100) class - compared to other classes, this group was the least likely to donate in the same category. Still, past donations seem to be important in predicting future donations.


## EDA - Interaction between last year's donations and overall donations in predicting 2016 donations

```{r}
ggp <- ggplot(labdata, aes(x=log(meandonation+1)/log(10), y=log(FY16Giving+1)/log(10), 
                           group=FY15cat, color=FY15cat))

ggp + geom_point() + geom_smooth(method="lm", se=F)+
  xlab("Mean donation 2012-2015 (dollars)")+ylab("2016 donation (dollars)")+
  scale_x_continuous(breaks=c(0,1,2,3,4), labels=c("0", "10", "100", "1,000", "10,000"))+
    scale_y_continuous(breaks=c(0,1,2,3,4), labels=c("0", "10", "100", "1,000", "10,000"))
```

Above is a scatterplot with the mean donation from 2012-2015 on the x-axis and the amount donated in 2016 on the y-axis. (While we are analyzing 2016 donations in categories, we thought this visualization was best done with the dollar amount). Overall, there is a clear relationship between mean donation and amount donated in 2016 - alumni typically didn't donate a drastically different amount in 2016 compared to how they've donated in years past. Of course, the exceptions are the many alumni who didn't donate in 2016 despite donating in years past (the dots on the horizontal x=0 line). There are a lot less alumni who donated in 2016 for the first time (the dots on the vertical y=0 line)

The purpose of the different colors/trend lines is to examine an interaction effect we found interesting and potentially useful for our model. The lines seem to generally be parallel except for the one representing the [0,1) category. The implication of this is that for alumni who donated in 2015, it is easier to predict their 2016 donations from their previous years, but for alumni who did not donate in 2015 the relationship is less clear. Rather than modeling an interaction term for each category for 2015, which could get too complex, it seems the interaction comes from whether they donated at all last year or not, which is why we will model their 2015 donations as a binary variable.


# Statistical Modelling

## Modeling

We examined both multinomial and ordinal regression models. In the following sections we explain our modelling steps, the model progression we went through and final model selection.

## Explanation vs Prediction

As we mentioned before, the overall goal of the current work is prediction of future donations rather than explanation of the factors that drive donation. Given that, we choose to choose models based on their predictive power rather than their explanatory power. 

For the same reason, we take a machine learning approach to model welection, where We split the data into a test and training set allowing us to test the accuracy of the model. 


```{r}
library(car)
set.seed(107)
sample <- sample.int(n = nrow(labdata), size = floor(.75*nrow(labdata)), replace = F)
train <- labdata[sample, ]
test  <- labdata[-sample, ]
```

### Base Multinomial Model

Even though our dependent variable is ordinal, it has a categorical nature and sometimes multinomial models can excel at modelling this data.

Initially we started with a model with most of the original predictors from the data included in our EDA. 

```{r}
mn.model <- multinom(FY16cat ~ AttendenceEvent + Gender + Class.Year  + Marital.Status + NextDegreeBinary + FY12Giving + FY13Giving + FY14Giving + FY15Giving, data=train)
mn.model$AIC
```

We can now do hypothesis testing, in this case through analysis of variance.

```{r}
Anova(mn.model)
```

Using analysis of variance test we obtain the analysis of deviance table, where we can see that for all variables except for FY14Giving and Gender, we can reject the null hypothesis that the $\beta$ parameter for those predictors is $0$.

To understand strengths and weaknesses of our base model, we use a confusion matrix, which provides rich information about what categories we fail to predict, where we do well, etc.

```{r}
mn.preds <- predict(mn.model, test, type="class")
confusionMatrix(mn.preds, test$FY16cat)
```


The confusion matrix shows that the model is better at predicting the [0,1) and the [500, 2e+05) groups and has trouble with the middle groups, specifically the [250,500).  This group has a small sample size in our dataset which would make this group harder to predict.


## Multinomial Model

We now aim to improve our model using engineers features from our EDA. Interestingly, features that we believed would increase our predictive power, actually had a very positive impact in the overall performance of our model.

```{r}
mn.model <- multinom(FY16cat ~ AttendenceEvent + Gender + NextDegreeBinary + as.ordered(YearsSinceGrad) + log(meandonation+1) * gaveLastYear, data=train)
summary(mn.model)
```
f
We can see that were able to reduce the model AIC to 1168 and reduce the features. Reducing the number of features should help with not overfitting the model on a relatively small sample set. We removed marital status because of small sample sizes for the Widow and Divorced groups. The addition of $log(meandonation+1)$ and $gaveLastYear$ provide powerful and yet concise insights on the past donation history.

```{r}
Anova(mn.model)
```

Analyzing the deviance table, we can boserve that attendence to recruiting events and years since graduation do not pass the likelihood test, accepting the null hypothesis that the coefficient for those predictors is zero. However, from a domain knowledge perspective we feel that those variables are important, and that is confirmed by the improved prediction power of our model, which we can analyze by showing its confusion matrix.

```{r}
mn.preds <- predict(mn.model, test, type="class")
confusionMatrix(mn.preds, test$FY16cat)
```

The confusion matrix shows a greatly improved overall acuracy with at 67.6% with a 95% confidence between 61.4% and 73.3%.  We also see an improvement in the sensitivity for the highest donor group, which to us is one of the most important groups to get correctly predicted. It is important to be able to identify individuals in this group since they account for ~77% of donations in 2016.

## Ordinal Model

Our final model was an oridinal model, using the same predictors as our improved multinomial model. The ordinal model improved slightly on overall accuracy with our test set scoring a 68.8%. The ordinal model showed improvements particularly the sensitivity and specificity scores for the highest donor and the non-donor groups. 

### Final Model Selection: Ordinal model

To select and compare models, we used statistical analysis such as AIC and hypothesis testing, but also we took a holistic approach by analyzing confusion matrices for each model and understanding and interpreting each model's strengths and weaknesses. Particularly, we felt that detecting individuals that donated in the highest amount group and individuals that don't donate at all was very valuable, while differentiating between the two middle donation brackets was not so important. Not only that, but ~70% of donations during 2016 were in the highest bracket and the non-donor group was the majority of our sample, so even a better reason to prioritize the correct prediction of those group. Confusion matrices allow us to compare how each model did on each group, which is valuable given our approach. 

```{r}
ord.model <- clm(FY16cat ~ AttendenceEvent + Gender + NextDegreeBinary + as.ordered(YearsSinceGrad) + log(meandonation+1) * gaveLastYear, data=train)
summary(ord.model)
```


Note that the ordinal model also maintains the parsimony of the previous model, using the same predictors. We can observe that most variables are statistically significant, except for attendenceEven, Gender, and some levels of the years since graduation. However, these variables proved to be quite valuable in our EDA, and furthermore we did formal hypothesis testing of removing them, and the model with them proved to be better, and also had better predictive power which again is our focus in this study.

```{r}
Anova(ord.model)
```

We can now analyze the analysis of deviance table above for the ordinal model, where the null hypothesis is that the $\beta$ coefficient for each predictor is $0$ and the alternate hypothesis is that $\beta \ne 0$. Note that we fail to reject the null hypothesis for the $log(meandonation + 1)$ and for the interaction term. However these terms proved to have great predictive power, and greatly increase the parsimony of our model. 

```{r}
ord.preds <- predict(ord.model, test, type="class")
confusionMatrix(ord.preds$fit, test$FY16cat)
```

We can observe that this confusion matrix yields not only the best accuracy of all our models, but also the best predictions for the highest and lowest donation bracket, which is aligned with our goals for this study.

Another interesting thing about the ordinal model presented is that the failures to predict tend to be in categories that are close in terms of domain meaning, for example, a mispredicted high donator may really be a moderate donator, but errors tend to group around the nearby categories of the expected one. On the contrary in the multinomial model we observe slightly more deviation in the errors, which makes sense from an interpretative point of view since in the ordinal model we are bringing in information about the order of the output categories.

## Final Remarks

In our analysis we have shown the relationships between several independent variables and the 2016 donations of alumni, and shown our model to have good predictive power for several of the categories. Overall, our model is able to predict donors vs. non-donors with high accuracy. Both previous donation patterns, as well as other factors like attending alumni events and having an advanced degree, allow us to discriminate between those who donated nothing in 2016 and those who donated something.

An additional goal of the model was to be able to predict which category of donation an alumnus would fall under, which would allow fundraising campaigns to not only target alumni who will donate but also pick out those who are likely to donate the most. In that regard our model fares more poorly. We are able to predict who will fall into the highest bucket of donation [500,2e+05) fairly well, as alumni who donate that much tend to do it on a yearly basis. However, our model struggled with accurately predicting the other three categories. A big reason for this is the sample size. Out of 1000 alumni, only 39 donated in the [250,500) category, which contributes to the lack of accuracy in predicting that particular category.

The administration can gain insight from our model on alumni who will donate vs. those who won't. It is clear that previous donation patterns have an influence on future donation paterns, and those should be taken as the most important predictive factors. It would be particularly useful to focus efforts on alumni who have donated the year before. But the administration can also use the information from our model to target those who attend alumni events and those with an advanced degree. The trend of older alumni donating more is also interesting. Presumably older alumni have larger incomes and therfore are able to donate more, and would be a good group to focus efforts on.

There is a lot of information that, if made available, would improve the quality of our models significantly. Many of the trends we noticed appear to have to do with income - those with an advanced degree, as well as older alumni, probably have larger incomes and can donate more. If the administration was able to collect information about income - or, more realistically, employment status of some sort - that information could be very useful. Another piece of information that could help would be involvement of the alumni while they were in college. One would expect that alumni that were more involved in extracurriculars - sports, theater, student government, etc. - would feel a greater connection to their university and therefore be more likely to donate. Race would also be an interesting variable to investigate; while we don't have an a priori hypothesis for its effect on donation, if the information was available it could potentially be useful. Finally, it would be useful to have information about their family's relationship to the university. If an alumnus was married to another alumnus, or has children who attend the university, that would likely increase the chances of them donating.

One final note is that the buckets chosen for the FY16Giving do not fit the data well. Unless the buckets represent some well-established standard, we believe that better buckets could be constructed to represent the distribution of donations more evenly. As mentioned before, a big challenge for the model was how sparsely represented some of the categories were, and slicing the data in a different way could improve our models substantially.
